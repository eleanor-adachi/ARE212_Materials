{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team's code can be found here: https://github.com/eleanor-adachi/ARE212_Materials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exercises (Identifying Assumptions for Regression)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wright (1928)\n",
    "\n",
    "Consider the canonical demand and supply model in which quantity supplied is a function of price and a set of \"supply shifters\"; quantity demanded is a function of price and set of \"demand shifters\"; and market clearing implies that at some price quantity demanded is equal to quantity supplied. A linear version of this model is fully specified and solved in [this Jupyter Notebook](https://github.com/ligonteaching/ARE212_Materials/blob/master/wright34.ipynb).\n",
    "\n",
    "Consider the following questions:\n",
    "\n",
    "1. (Control) What is the expected demand if we set the price $p = p_0$?\n",
    "\n",
    "2. (Condition) What is the expected demand if we observe $p = p_0$?\n",
    "\n",
    "3. (Counterfactual) If prices and quantities are observed to be $(p_0, q_0)$, what would demand be if we were to change the price to $p_1$, ceteris paribus?\n",
    "\n",
    "Answers could be mathematical expressions, or code that answers the question for the model given in the Jupyter notebook.\n",
    "\n",
    "### (1) (Control) What is the expected demand if we set the price $p = p_0$?\n",
    "\n",
    "First, recreate the linear model in [wright34.ipynb](https://github.com/ligonteaching/ARE212_Materials/blob/master/wright34.ipynb) representing:\n",
    "\n",
    "$$\n",
    "   q_D = \\alpha p + u\\qquad q_S = \\beta p + v\\qquad q_D = q_S,\n",
    "$$\n",
    "\n",
    "where $u$ and $v$ have normal distributions of the form:\n",
    "\n",
    "$F_u(u) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{−\\frac{(u − \\mu)^2}{2\\sigma^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import distributions as iid\n",
    "\n",
    "# Structural parameters;\n",
    "(α,β) = (-1,2)     \n",
    "σ = {'u':1/2,'v':1/3}\n",
    "μ = {'u':2,'v':-1}\n",
    "\n",
    "# u,v assumed independent\n",
    "u = iid.norm(loc=μ['u'], scale=σ['u'])  # Demand shocks\n",
    "v = iid.norm(loc=μ['v'], scale=σ['v'])  # Supply shocks\n",
    "\n",
    "# Reduced form coefficients\n",
    "π = [[-β/(α - β), -1/(α - β)],\n",
    "     [ α/(α - β), 1/(α - β)]]\n",
    "\n",
    "# Generate N realizations of system\n",
    "# Outcomes Y have columns (q,p)\n",
    "N = 10\n",
    "\n",
    "# Arrange shocks into an Nx2 matrix\n",
    "U = np.c_[u.rvs(N), v.rvs(N)]\n",
    "\n",
    "# Matrix product gives [q,p]; label by putting into df\n",
    "df = pd.DataFrame(U@π,columns=['q','p'])\n",
    "Udf = pd.DataFrame(U,columns=['u','v']) # For future reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, visualize by plotting demand curve segments that intersect $p_0$ for different realizations of $u$.\n",
    "\n",
    "Here, we show $p_0 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p0 = 1\n",
    "\n",
    "Q = pd.DataFrame({'min': α*(p0-0.3) + Udf['u'],\n",
    "                  'max': α*(p0+0.3) + Udf['u'],\n",
    "                  'miss':-1})\n",
    "\n",
    "# Inverse counterfactual demand & supply (for plotting)\n",
    "D = Q.add(-Udf['u'],axis=0)/α  \n",
    "\n",
    "counterfactual=pd.DataFrame({'D':D.stack(),\n",
    "                             'Q':Q.stack()})\n",
    "\n",
    "counterfactual=counterfactual.replace(-1,np.nan)\n",
    "\n",
    "_ = counterfactual.plot(x='Q')\n",
    "plt.axhline(y = p0, color = 'r', linestyle = '--', label='$p_0$')\n",
    "plt.ylabel('p')\n",
    "plt.title('Demand curves for different realizations of $u$')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that setting the price at $p = p_0$ has no effect on the distribution of $u$.\n",
    "\n",
    "Show probability distribution function of $u$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.linspace(0,4,100).tolist()\n",
    "\n",
    "plt.plot(X, [u.pdf(z) for z in X])\n",
    "plt.xlabel('$u$')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Distribution Function of $u$')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate expected demand:\n",
    "\n",
    "$\\mathbb{E}(q_D(p_0)) = \\int_{}^{} q_D(p_0, u)dF_u(u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "D_exp = quad(lambda x: (α*p0 + x)*u.pdf(x), -np.inf, np.inf)\n",
    "\n",
    "D_exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) (Condition) What is the expected demand if we observe $p = p_0$?\n",
    "\n",
    "Note that many possible combinations of $u$ and $v$ can result in observing $p_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take u as given\n",
    "\n",
    "# Find v such that p=p0 for given u\n",
    "v0 = (α - β)*p0 + Udf['u']\n",
    "\n",
    "Q = pd.DataFrame({'min': np.minimum(α*(p0-0.3) + Udf['u'], β*(p0+0.3) + v0),\n",
    "                  'max': np.maximum(α*(p0+0.3) + Udf['u'], β*(p0-0.3) + v0),\n",
    "                  'miss':-1})\n",
    "\n",
    "# Inverse counterfactual demand & supply (for plotting)\n",
    "D = Q.add(-Udf['u'],axis=0)/α  \n",
    "S = Q.add(-v0,axis=0)/β\n",
    "\n",
    "counterfactual=pd.DataFrame({'S':S.stack(),\n",
    "                             'D':D.stack(),\n",
    "                             'Q':Q.stack()})\n",
    "\n",
    "counterfactual=counterfactual.replace(-1,np.nan)\n",
    "\n",
    "_ = counterfactual.plot(x='Q')\n",
    "plt.axhline(y = p0, color = 'r', linestyle = '--', label='$p_0$')\n",
    "plt.ylabel('p')\n",
    "plt.title('Possible observed supply and demand at $p_0$')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected quantity demanded:\n",
    "\n",
    "$\\mathbb{E}[q^*(u,v) | q_D(p_0, u)=q_S(p_0, v)]$\n",
    "\n",
    "Need to find joint probability of $u$ and $v$???\n",
    "\n",
    "$q^* = -\\frac{\\beta}{\\alpha-\\beta}u -\\frac{1}{\\alpha-\\beta}v$\n",
    "\n",
    "$f_{q^*}(q^*) = f_u(u)|\\frac{\\partial u}{\\partial q^*}| \\cdot f_v(v)|\\frac{\\partial v}{\\partial q^*}|$\n",
    "\n",
    "$f_{q^*}(q^*) = f_u(u)|-\\frac{\\alpha-\\beta}{\\beta}| \\cdot f_v(v)|-\\frac{\\alpha-\\beta}{1}|$\n",
    "\n",
    "Let $v = -\\beta u - (\\alpha - \\beta) q^*$\n",
    "\n",
    "$f_{q^*}(q^*) = \\int_{-\\infty}^{\\infty} -\\frac{\\alpha-\\beta}{\\beta} f_u(u) (-\\frac{\\alpha-\\beta}{1}) f_v(-\\beta u - (\\alpha - \\beta) q^*) \\,du$\n",
    "\n",
    "$f_{q^*}(q^*) = \\int_{-\\infty}^{\\infty} \\frac{(\\alpha-\\beta)^2}{\\beta} f_u(u) f_v(-\\beta u - (\\alpha - \\beta) q^*) \\,du$\n",
    "\n",
    "Getting messy..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*New approach...*\n",
    "\n",
    "When $q_S = q_D$, then $\\alpha p + u = \\beta p + v$\n",
    "\n",
    "Let $v = u + (\\alpha - \\beta)p$\n",
    "\n",
    "$f_{q^*}(u) = f_u(u) \\cdot f_v(v)|\\frac{\\partial v}{\\partial u}|$\n",
    "\n",
    "$\\mathbb{E}[q^*(u,v) | q_D(p_0, u)=q_S(p_0, v)] = \\int_{}^{} q_D(p_0, u)dF_u(u)dF_v(u + (\\alpha - \\beta)p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine q_D and v in terms of u\n",
    "D_exp = quad(lambda x: (α*p0 + x)*u.pdf(x)*v.pdf(x + (α - β)*p0), -np.inf, np.inf)\n",
    "D_exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Angrist-Krueger (1991) Replication\n",
    "\n",
    "### (1) What is the (implicit) identifying assumption? Comment on its plausibility.\n",
    "\n",
    "The implicit identifying assumption in Angrist and Krueger's study is that the season of birth (or quarter of birth) is exogenously determined and is not systematically related to other unobserved individual characteristics that affect educational attainment and earnings. This assumption means that being born in a particular part of the year should not directly affect one's educational outcomes or earnings potential, other than through the mechanisms of school entry age and compulsory schooling laws.\n",
    "\n",
    "This identifying assumption seems highly plausible given that parents are unlikely to be able to precisely plan the birth month of their children. \n",
    "\n",
    "It is possible that this assumption could be violated if children born in certain seasons are at different developmental stages when they start school, which could influence their educational progress and, subsequently, their earnings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Using their data, estimate (2), replicating the figures in their Table 5, using the conventional two-stage least squares IV estimator (what they call TSLS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1933 1930 1937 1935 1938 1939 1936 1934 1931 1932]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import inv, sqrtm\n",
    "import statsmodels.api as sm\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# Read in the data file\n",
    "ak_data = pd.read_stata('../../angrist-krueger91.dta')\n",
    "# Print distinct years in the data\n",
    "print(ak_data['yob'].unique()) # Years are already filtered to 1930-1939 cohort\n",
    "# Add a constant to the data\n",
    "ak_data = sm.add_constant(ak_data)\n",
    "# Add dummy variables for each year of birth and each region minus one \n",
    "ak_data = pd.get_dummies(ak_data, columns=['yob', 'region', 'qob'], drop_first=True) \n",
    "# Dummy variables get coded as boolean - recode as 0/1 dummies\n",
    "for column in ak_data.columns:\n",
    "    if ak_data[column].dtype == 'bool':\n",
    "        ak_data[column] = ak_data[column].astype(int)\n",
    "ak_data['ageq_sq'] = ak_data['ageq']**2\n",
    "# Create yob*qob interaction terms\n",
    "for i in range(9):\n",
    "    for j in range(3):\n",
    "        ak_data['yob_193'+str(i+1)+'_qob_'+str(j+2)] = ak_data['yob_193'+str(i+1)]*ak_data['qob_'+str(j+2)]     \n",
    "# Create outcome variable equal to log wage\n",
    "y = ak_data[['logwage']]\n",
    "# Create regressor list for ease when creating regressions\n",
    "yob_dummies = ['yob_1931', 'yob_1932', 'yob_1933', 'yob_1934', 'yob_1935', 'yob_1936', 'yob_1937', 'yob_1938', 'yob_1939']\n",
    "region_dummies = ['region_1.0', 'region_2.0', 'region_3.0', 'region_4.0', 'region_5.0', 'region_6.0', 'region_7.0', 'region_8.0']\n",
    "qob_dummies = ['qob_2', 'qob_3', 'qob_4']\n",
    "interaction_dummies = [\n",
    "    'yob_1931_qob_2','yob_1931_qob_3','yob_1931_qob_4','yob_1932_qob_2','yob_1932_qob_3','yob_1932_qob_4',\n",
    "    'yob_1933_qob_2','yob_1933_qob_3','yob_1933_qob_4','yob_1934_qob_2','yob_1934_qob_3','yob_1934_qob_4',\n",
    "    'yob_1935_qob_2','yob_1935_qob_3','yob_1935_qob_4','yob_1936_qob_2','yob_1936_qob_3','yob_1936_qob_4',\n",
    "    'yob_1937_qob_2','yob_1937_qob_3','yob_1937_qob_4','yob_1938_qob_2','yob_1938_qob_3','yob_1938_qob_4',\n",
    "    'yob_1939_qob_2','yob_1939_qob_3','yob_1939_qob_4'\n",
    "]\n",
    "\n",
    "# The 'state' variable for some reason goes from 1-56, with some missing values (e.g. 3 is missing).\n",
    "# We will recode this variable to start from 1 and be sequential\n",
    "# Get the unique state codes from the 'state' column, sorted\n",
    "unique_states = sorted(ak_data['state'].unique())\n",
    "# Create a mapping from old state codes to new sequential codes starting from 1\n",
    "state_mapping = {old_code: new_code for new_code, old_code in enumerate(unique_states, start=1)}\n",
    "# Now apply this mapping to the 'state' column to create a new 'state' column\n",
    "ak_data['state_recode'] = ak_data['state'].map(state_mapping)\n",
    "\n",
    "# Create dummy variables from the new sequential state column\n",
    "ak_data = pd.get_dummies(ak_data, columns=['state_recode'], drop_first=True)\n",
    "# Ensure all boolean columns are converted to integers\n",
    "for column in ak_data.columns:\n",
    "    if ak_data[column].dtype == bool:\n",
    "        ak_data[column] = ak_data[column].astype(int)\n",
    "        \n",
    "# Create qob*state interaction terms\n",
    "\n",
    "# Number of qobs and states\n",
    "num_qobs = 4\n",
    "num_states = 51\n",
    "for i in range(2, num_qobs + 1):  # qobs start from 2 since the first qob is dropped\n",
    "    for j in range(2, num_states + 1):  # states start from 2 since the first state is dropped\n",
    "        qob_col = f'qob_{i}'\n",
    "        state_col = f'state_recode_{j}'\n",
    "        interaction_col = f'{qob_col}_state_{j}'\n",
    "        if qob_col in ak_data.columns and state_col in ak_data.columns:\n",
    "            ak_data[interaction_col] = ak_data[qob_col] * ak_data[state_col]\n",
    "        else:\n",
    "            print(f\"Column does not exist: {qob_col} or {state_col}\")\n",
    "\n",
    "# Create the state and state_qob_interactions lists\n",
    "state_dummies = [f'state_recode_{i}' for i in range(2, num_states + 1)]\n",
    "state_qob_interactions = [f'qob_{i}_state_{j}' for i in range(2, num_qobs + 1) for j in range(2, num_states + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS function\n",
    "def OLS(Y,X):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    XX = np.transpose(X)@X\n",
    "    XX_inv = np.linalg.pinv(XX)\n",
    "    XY = np.transpose(X)@Y\n",
    "    Beta_OLS = XX_inv@XY\n",
    "    N = Y.shape[0]\n",
    "    resid = Y - X@Beta_OLS \n",
    "    resid_var = (np.sum(np.square(resid)))/(N-1)\n",
    "    var_covar = resid_var*XX_inv \n",
    "    K = XX.shape[0]\n",
    "    SE = np.zeros(K)\n",
    "    for i in range(K):\n",
    "          SE[i] = np.sqrt(var_covar[i,i])\n",
    "    t = (1/SE)*Beta_OLS\n",
    "    return Beta_OLS, SE, var_covar,t\n",
    "\n",
    "# IV (2SLS) estimator function:\n",
    "def IV2SLS(Y,X,Z):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Z = np.array(Z)\n",
    "    ZX = np.transpose(Z)@X\n",
    "    ZX_inv = np.linalg.pinv(ZX)\n",
    "    ZY = np.transpose(Z)@Y\n",
    "    ZZ = np.transpose(Z)@Z\n",
    "    ZZ_inv = np.linalg.pinv(ZZ)\n",
    "    Beta_IV2SLS = np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)@(np.transpose(ZX)@ZZ_inv@ZY)\n",
    "    e = Y - X@Beta_IV2SLS\n",
    "    SSR = np.transpose(e)@e\n",
    "    N = X.shape[0]\n",
    "    vcv_IV2SLS = (SSR/N)*np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)\n",
    "    K = X.shape[1]\n",
    "    SE_IV2SLS = np.zeros(K)\n",
    "    for i in range(K):\n",
    "          SE_IV2SLS[i] = np.sqrt(vcv_IV2SLS[i,i])\n",
    "    t_IV2SLS = (1/SE_IV2SLS)*Beta_IV2SLS\n",
    "    return Beta_IV2SLS, SE_IV2SLS, vcv_IV2SLS,t_IV2SLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0711\n",
      "Education OLS SE: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# First OLS regression - Column 1\n",
    "# Regress log wage on a constant, education, and YOB dummies\n",
    "X1 = ak_data[['const', 'edu'] + yob_dummies]\n",
    "OLS1 = OLS(y,X1)\n",
    "Coeff1 = OLS1[0]\n",
    "SE1 = OLS1[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff1[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE1[1],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.0891\n",
      "Education TSLS SE: 0.0161\n"
     ]
    }
   ],
   "source": [
    "# First 2SLS regression - Column 2\n",
    "\n",
    "# First stage regression of a constant, YOB dummies, QOB dummies, and the interaction of the two\n",
    "Z1 = ak_data[['const'] + yob_dummies + qob_dummies + interaction_dummies]\n",
    "TSLS1 = IV2SLS(y,X1,Z1)\n",
    "Coeff_TSLS1 = TSLS1[0]\n",
    "SE_TSLS1 = TSLS1[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS1[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS1[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0711\n",
      "Education OLS SE: 0.0003\n",
      "Age OLS estimate:  -0.0772\n",
      "Age OLS SE: 0.0621\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Second OLS Regression - Column 3\n",
    "\n",
    "X2 = ak_data[['const', 'edu', 'ageq', 'ageq_sq'] + yob_dummies]\n",
    "OLS2 = OLS(y,X2)\n",
    "Coeff2 = OLS2[0]\n",
    "SE2 = OLS2[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2[1],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff2[2][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE2[2],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff2[3][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE2[3],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.076\n",
      "Education TSLS SE: 0.029\n",
      "Age TSLS estimate:  -0.0801\n",
      "Age TSLS SE: 0.0645\n",
      "Age Squared TSLS estimate:  0.0008\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Second 2SLS - Column 4\n",
    "Z2 = ak_data[['const', 'ageq', 'ageq_sq'] + yob_dummies + qob_dummies + interaction_dummies]\n",
    "TSLS2 = IV2SLS(y,X2,Z2)\n",
    "Coeff_TSLS2 = TSLS2[0]\n",
    "SE_TSLS2 = TSLS2[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS2[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS2[1],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff_TSLS2[2][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE_TSLS2[2],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff_TSLS2[3][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE_TSLS2[3],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0632\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2575\n",
      "Race OLS SE: 0.004\n",
      "SMSA OLS estimate:  0.1763\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2479\n",
      "Married OLS SE: 0.0032\n"
     ]
    }
   ],
   "source": [
    "# Third OLS - Column 5\n",
    "X3 = ak_data[['const', 'edu', 'black', 'smsa', 'married'] + yob_dummies + region_dummies]\n",
    "OLS3 = OLS(y,X3)\n",
    "Coeff3 = OLS3[0]\n",
    "SE3 = OLS3[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff3[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE3[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff3[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE3[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff3[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE3[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff3[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE3[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.0806\n",
      "Education TSLS SE: 0.0164\n",
      "Race TSLS estimate:  -0.2302\n",
      "Race TSLS SE: 0.0261\n",
      "SMSA TSLS estimate:  0.1581\n",
      "SMSA TSLS SE: 0.0174\n",
      "Married TSLS estimate:  0.244\n",
      "Married TSLS SE: 0.0049\n"
     ]
    }
   ],
   "source": [
    "# Third 2SLS - Column 6\n",
    "Z3 = ak_data[['const', 'black', 'smsa', 'married'] + yob_dummies + region_dummies + qob_dummies + interaction_dummies]\n",
    "TSLS3 = IV2SLS(y,X3,Z3)\n",
    "Coeff_TSLS3 = TSLS3[0]\n",
    "SE_TSLS3 = TSLS3[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS3[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS3[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff_TSLS3[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE_TSLS3[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff_TSLS3[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE_TSLS3[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff_TSLS3[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE_TSLS3[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0632\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2575\n",
      "Race OLS SE: 0.004\n",
      "SMSA OLS estimate:  0.1763\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2479\n",
      "Married OLS SE: 0.0032\n",
      "Age OLS estimate:  -0.076\n",
      "Age OLS SE: 0.0604\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth OLS - Column 7\n",
    "X4 = ak_data[['const', 'edu', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies]\n",
    "OLS4 = OLS(y,X4)\n",
    "Coeff4 = OLS4[0]\n",
    "SE4 = OLS4[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff4[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE4[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff4[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE4[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff4[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE4[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff4[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE4[4],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff4[5][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE4[5],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff4[6][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE4[6],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.05995\n",
      "Education TSLS SE: 0.029\n",
      "Race TSLS estimate:  -0.2626\n",
      "Race TSLS SE: 0.0458\n",
      "SMSA TSLS estimate:  0.1797\n",
      "SMSA TSLS SE: 0.0305\n",
      "Married TSLS estimate:  0.2486\n",
      "Married TSLS SE: 0.0073\n",
      "Age TSLS estimate:  -0.0741\n",
      "Age TSLS SE: 0.0626\n",
      "Age Squared TSLS estimate:  0.0007\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth 2SLS - Column 8\n",
    "Z4 = ak_data[['const', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + qob_dummies + interaction_dummies]\n",
    "TSLS4 = IV2SLS(y,X4,Z4)\n",
    "Coeff_TSLS4 = TSLS4[0]\n",
    "SE_TSLS4 = TSLS4[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS4[1][0],5))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS4[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff_TSLS4[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE_TSLS4[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff_TSLS4[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE_TSLS4[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff_TSLS4[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE_TSLS4[4],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff_TSLS4[5][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE_TSLS4[5],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff_TSLS4[6][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE_TSLS4[6],4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Repeat (2), but for the specification reported in their Table 7 (which has many more instruments). Summarize what the above exercises tell us about returns to education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0673\n",
      "Education OLS SE: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# First OLS regression - Column 1\n",
    "# Regress log wage on a constant, education, and YOB dummies\n",
    "X2_1 = ak_data[['const', 'edu'] + yob_dummies + state_dummies] \n",
    "OLS2_1 = OLS(y,X2_1)\n",
    "Coeff2_1 = OLS2_1[0]\n",
    "SE2_1 = OLS2_1[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2_1[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2_1[1],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.0976\n",
      "Education TSLS SE: 0.0103\n"
     ]
    }
   ],
   "source": [
    "# First 2SLS regression - Column 2\n",
    "\n",
    "Z2_1 = ak_data[['const'] + yob_dummies + qob_dummies + state_qob_interactions + interaction_dummies]\n",
    "TSLS2_1 = IV2SLS(y,X2_1,Z2_1)\n",
    "Coeff_TSLS2_1 = TSLS2_1[0]\n",
    "SE_TSLS2_1 = TSLS2_1[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS2_1[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS2_1[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0673\n",
      "Education OLS SE: 0.0003\n",
      "Age OLS estimate:  -0.0757\n",
      "Age OLS SE: 0.0617\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Second OLS Regression - Column 3\n",
    "\n",
    "X2_2 = ak_data[['const', 'edu', 'ageq', 'ageq_sq'] + yob_dummies + state_dummies] \n",
    "OLS2_2 = OLS(y,X2_2)\n",
    "Coeff2_2 = OLS2_2[0]\n",
    "SE2_2 = OLS2_2[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2_2[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2_2[1],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff2_2[2][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE2_2[2],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff2_2[3][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE2_2[3],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.0907\n",
      "Education TSLS SE: 0.0107\n",
      "Age TSLS estimate:  -0.088\n",
      "Age TSLS SE: 0.0624\n",
      "Age Squared TSLS estimate:  0.0009\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Second 2SLS - Column 4\n",
    "Z2_2 = ak_data[['const', 'ageq', 'ageq_sq'] + yob_dummies + qob_dummies + state_qob_interactions + state_dummies + interaction_dummies]\n",
    "TSLS2_2 = IV2SLS(y,X2_2,Z2_2)\n",
    "Coeff_TSLS2_2 = TSLS2_2[0]\n",
    "SE_TSLS2_2 = TSLS2_2[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS2_2[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS2_2[1],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff_TSLS2_2[2][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE_TSLS2_2[2],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff_TSLS2_2[3][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE_TSLS2_2[3],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0628\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2547\n",
      "Race OLS SE: 0.0043\n",
      "SMSA OLS estimate:  0.1705\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2487\n",
      "Married OLS SE: 0.0032\n"
     ]
    }
   ],
   "source": [
    "# Third OLS - Column 5\n",
    "X2_3 = ak_data[['const', 'edu', 'black', 'smsa', 'married'] + yob_dummies + region_dummies + state_dummies]\n",
    "OLS2_3 = OLS(y,X2_3)\n",
    "Coeff2_3 = OLS2_3[0]\n",
    "SE2_3 = OLS2_3[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2_3[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2_3[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff2_3[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE2_3[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff2_3[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE2_3[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff2_3[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE2_3[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.0831\n",
      "Education TSLS SE: 0.0095\n",
      "Race TSLS estimate:  -0.2333\n",
      "Race TSLS SE: 0.0109\n",
      "SMSA TSLS estimate:  0.1511\n",
      "SMSA TSLS SE: 0.0095\n",
      "Married TSLS estimate:  0.2435\n",
      "Married TSLS SE: 0.004\n"
     ]
    }
   ],
   "source": [
    "# Third 2SLS - Column 6\n",
    "Z2_3 = ak_data[['const', 'black', 'smsa', 'married'] + yob_dummies +  region_dummies + qob_dummies + state_dummies + state_qob_interactions + interaction_dummies]\n",
    "TSLS2_3 = IV2SLS(y,X2_3,Z2_3)\n",
    "Coeff2_TSLS3 = TSLS2_3[0]\n",
    "SE2_TSLS3 = TSLS2_3[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff2_TSLS3[1][0],4))\n",
    "print(\"Education TSLS SE:\", np.round(SE2_TSLS3[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff2_TSLS3[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE2_TSLS3[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff2_TSLS3[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE2_TSLS3[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff2_TSLS3[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE2_TSLS3[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0628\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2547\n",
      "Race OLS SE: 0.0043\n",
      "SMSA OLS estimate:  0.1705\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2487\n",
      "Married OLS SE: 0.0032\n",
      "Age OLS estimate:  -0.0778\n",
      "Age OLS SE: 0.0603\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth OLS - Column 7\n",
    "X2_4 = ak_data[['const', 'edu', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + state_dummies]\n",
    "OLS2_4 = OLS(y,X2_4)\n",
    "Coeff2_4 = OLS2_4[0]\n",
    "SE2_4 = OLS2_4[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2_4[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2_4[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff2_4[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE2_4[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff2_4[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE2_4[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff2_4[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE2_4[4],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff2_4[5][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE2_4[5],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff2_4[6][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE2_4[6],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.08106\n",
      "Education TSLS SE: 0.0109\n",
      "Race TSLS estimate:  -0.2354\n",
      "Race TSLS SE: 0.0122\n",
      "SMSA TSLS estimate:  0.1531\n",
      "SMSA TSLS SE: 0.0107\n",
      "Married TSLS estimate:  0.2441\n",
      "Married TSLS SE: 0.0042\n",
      "Age TSLS estimate:  -0.0876\n",
      "Age TSLS SE: 0.0609\n",
      "Age Squared TSLS estimate:  0.0009\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth 2SLS - Column 8\n",
    "Z2_4 = ak_data[['const', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + qob_dummies + interaction_dummies + state_dummies + state_qob_interactions]\n",
    "TSLS2_4 = IV2SLS(y,X2_4,Z2_4)\n",
    "Coeff2_TSLS4 = TSLS2_4[0]\n",
    "SE2_TSLS4 = TSLS2_4[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff2_TSLS4[1][0],5))\n",
    "print(\"Education TSLS SE:\", np.round(SE2_TSLS4[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff2_TSLS4[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE2_TSLS4[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff2_TSLS4[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE2_TSLS4[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff2_TSLS4[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE2_TSLS4[4],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff2_TSLS4[5][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE2_TSLS4[5],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff2_TSLS4[6][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE2_TSLS4[6],4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize what the above exercises tell us about returns to education.\n",
    "\n",
    "The above exercises tell us that an extra year of education significantly increases average wages. All of the regressions specifications include a positive coefficient on years of education. The TSLS estimates in table 7 are significantly larger than the OLS estimates. This indicates that the observed associated between schooling and earnings is not driven by omitted variables like family background or ability.\n",
    "\n",
    "**anything more to say here?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
