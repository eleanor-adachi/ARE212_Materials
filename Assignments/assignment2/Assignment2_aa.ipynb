{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18b5227",
   "metadata": {},
   "source": [
    "# Assignment 2_GROUP 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83865e",
   "metadata": {},
   "source": [
    "## 1.5 MSE\n",
    "\n",
    "#### Suppose that $y = f(X) + u$ for some unknown but continuous function $f$. Suppose we want to use observed data on $X$ to predict outcomes $y$, and seek a predictor $\\hat{y}(X)$ which is \"best\" in the sense that the (expected) mean squared prediction error $\\mathbb{E} [(y - \\hat{y}(X))^2 | X]$ is minimized.  What can we say about $\\hat{y}$ and its relation to the conditional expectation $\\mathbb{E}(y | X)$?  Its relation to $u$??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4154b4b",
   "metadata": {},
   "source": [
    "- $\\hat{y}(X)$  is equal to   $\\mathbb{E} [y | X] $\n",
    "\n",
    "\n",
    "$\\mathbb{E} [(y - \\hat{y}(X))^2 | X]$ = $\\mathbb{E} [(y^2 - 2y\\hat{y}(X) + \\hat{y}(X)^2 )| X]$\n",
    "\n",
    "Taking the derivative with respect to $\\hat{y}(X)$\n",
    "\n",
    "$-2\\mathbb{E}  [y | X] + 2\\hat{y}(X) = 0 $ -->  $\\mathbb{E} [y | X] = \\hat{y}(X) $\n",
    "\n",
    "Therefore the optimal predictor that minimizes the (expected) mean squared prediction error is the conditional expectation of $y$ given $X$.\n",
    "\n",
    "$y = f(X) + u$ \n",
    "\n",
    "- relation to $u$ \n",
    "\n",
    "The error term u is ideally supposed to be independent of X, meaning E(u∣X)=0. This ensures that the optimal predictor (X) does not need to adjust for any systematic bias in u that is related to X.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a96297",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Optimal Predictor $\\hat{y}(X)$\n",
    "- **Mean Squared Prediction Error**: The MSE for a predictor $\\hat{y}(X) $ is defined as:\n",
    "  $\\text{MSE} = E[(y - \\hat{y}(X))^2 | X] $\n",
    "  We aim to minimize this MSE.\n",
    "\n",
    "- **Expanding the MSE**: Expand the squared term:\n",
    "  $[(y - \\hat{y}(X))^2 = (f(X) + u - \\hat{y}(X))^2\\$\n",
    "\n",
    "Since $y = f(X) + u $, \n",
    "we see the deviation of the predictor from both the deterministic part $ f(X)$ and the stochastic component $u$.\n",
    "\n",
    "- **Optimal Condition**: To minimize the MSE, consider the expectation:\n",
    "  $E[(y - \\hat{y}(X))^2 | X] = E[(f(X) + u - \\hat{y}(X))^2 | X]$\n",
    "\n",
    "Deriving with respect to $\\hat{y}(X)$ and setting the derivative to zero gives us the condition for the optimal $\\hat{y}(X) :\\frac{\\partial}{\\partial \\hat{y}(X)} E[(f(X) + u - \\hat{y}(X))^2 | X] = 0$\n",
    "\n",
    "This yields $\\hat{y}(X) = E[f(X) + u | X] = \\mathbb{E} [y | X]$ since $E[u|X] = 0 $ if $u$ is uncorrelated with $ X $\n",
    "\n",
    "### Relation to $\\mathbb{E} [y | X] $\n",
    "\n",
    "- $ \\hat{y}(X) =\\mathbb{E} [y | X] $ is the best predictor of \\( y \\) given $X $ in terms of minimizing the MSE.\n",
    "\n",
    "### Relation to $ u $\n",
    "- **Uncorrelated Error**: The error term $ u $ is independent of $X $, meaning $ E(u|X) = 0$. This ensures that the optimal predictor $\\hat{y}(X)$ does not need to adjust for any systematic bias in $u$ that is related to $X $.\n",
    "\n",
    "\n",
    "In summary, the optimal predictor $ \\hat{y}(X)$ in terms of MSE minimization equals  $\\mathbb{E}(y | X)$,  assuming that $ u $ is independent of $ X $ --> $ E(u|X) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f1b28",
   "metadata": {},
   "source": [
    "## 3. “Plausibly Exogenous”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34798d65",
   "metadata": {},
   "source": [
    "### 3.1 IV Assumptions\n",
    "\n",
    "\n",
    "#### How it works; \n",
    "\n",
    "Initially we have an indogeneity Problem\n",
    "\n",
    "In the regression model `y = Xβ + u`, if `X` is correlated with `u`, then `E(X^Tu) ≠ 0`. Consequently, using OLS leads to biased estimates:\n",
    "\n",
    " $\\hat{\\beta}_{OLS} = (X^TX)^{-1}X^Ty = β + (X^TX)^{-1}X^Tu$\n",
    "\n",
    "This indicates that $\\hat{\\beta}_{OLS}$ also has the term $(X^TX)^{-1}X^Tu$, reflecting the correlation between X and u, and leading to potential bias.\n",
    "\n",
    "To solve this we use an instrumental Variable $Z$\n",
    "\n",
    "$\\hat{\\beta}_{IV} = (Z^TX)^{-1}Z^Ty$\n",
    "\n",
    "We first Estimate the predicted values $\\hat{X}$, using the projection of $X$ on $Z$, This step essentially purges X of the influences correlated with u, using Z as the source of exogenous variation.\n",
    "\n",
    "$\\hat{X} = Z(Z^TZ)^{-1}Z^TX$\n",
    "\n",
    "And then we regress $y$ on the predicted values $\\hat{X}$ to obtain $\\hat{β}_{IV}$, \n",
    "\n",
    "$\\hat{\\beta}_{IV} = (\\hat{X}^T\\hat{X})^{-1}\\hat{X}^Ty$\n",
    "\n",
    "\n",
    "#### Assumptions: \n",
    "\n",
    "The instrument $Z$ must satisfy 2 key assumptions\n",
    "\n",
    "- Relevance: $Z$ must be correllated with $X$. ($Z^TX ≠ 0$)\n",
    "- Exogeneity: $Z$ must be uncorrelated with the error term u. ($E(Z^Tu) = 0 $)\n",
    "- Exclusion Restriction: Z should affect y only through X and not directly. This assumption is crucial and often difficult to test directly.\n",
    "\n",
    "- Instrument Strength: Weak instruments can lead to poor estimates \n",
    "- Homoscedasticity and Other Statistical Properties: While not always necessary, assumptions regarding the distribution of error terms, such as homoscedasticity, can influence the efficiency and robustness of IV estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9194c",
   "metadata": {},
   "source": [
    "### 3.2 Conley et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4de527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import distributions as iid\n",
    "def linear_dgp(n, beta, gamma, sigma_u=1, rho=0.5):\n",
    "    \"\"\"\n",
    "    Generates data for the model y = Xβ + Zγ + u.\n",
    "    - n: Number of observations\n",
    "    - beta: Coefficient for X\n",
    "    - gamma: Coefficient for Z\n",
    "    - sigma_u: Standard deviation of the error term\n",
    "    - rho: Correlation between X and Z\n",
    "    \"\"\"\n",
    "    X = np.random.normal(0, 1, n)\n",
    "    Z = rho * X + np.sqrt(1 - rho**2) * np.random.normal(0, 1, n)\n",
    "    u = np.random.normal(0, sigma_u, n)\n",
    "    y = X * beta + Z * gamma + u\n",
    "    return y, X, Z\n",
    "\n",
    "def estimate_ols(y, X, Z):\n",
    "    \"\"\"\n",
    "    Estimates the OLS of the model y = Xβ + Zγ.\n",
    "    \"\"\"\n",
    "    predictors = sm.add_constant(np.column_stack((X, Z)))\n",
    "    model = sm.OLS(y, predictors).fit()\n",
    "    return model.params  # Returns estimates of β and γ\n",
    "\n",
    "# Simulation settings\n",
    "n = 1000\n",
    "beta = 1\n",
    "gammas = np.linspace(0, 1, 11)  # Values of γ to test\n",
    "\n",
    "# Arrays to store the results\n",
    "estimated_betas = []\n",
    "estimated_gammas = []\n",
    "\n",
    "# Conduct the simulation\n",
    "for gamma in gammas:\n",
    "    y, X, Z = linear_dgp(n, beta, gamma)\n",
    "    estimated_params = estimate_ols(y, X, Z)\n",
    "    estimated_betas.append(estimated_params[1])  # Estimated β\n",
    "    estimated_gammas.append(estimated_params[2])  # Estimated γ\n",
    "    print(f\"Gamma: {gamma:.2f}, Estimated Beta: {estimated_params[1]:.2f}, Estimated Gamma: {estimated_params[2]:.2f}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for Estimated Beta\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gammas, estimated_betas, 'bo-', label='Estimated Beta')\n",
    "plt.axhline(y=beta, color='red', linestyle='--', label='True Beta')\n",
    "plt.title('Estimated Beta vs. Gamma')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('Estimated Beta')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for Estimated Gamma\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(gammas, estimated_gammas, 'go-', label='Estimated Gamma')\n",
    "plt.axhline(y=0, color='red', linestyle='--', label='True Gamma = 0')\n",
    "plt.title('Estimated Gamma vs. Gamma')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('Estimated Gamma')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4084dd0",
   "metadata": {},
   "source": [
    "Estimated Gamma vs. Gamma: This graph shows a clear trend where the estimated $\\hatγ$ increases in line with the true $γ$. This suggests that the model is sensitive to changes in $γ$ and is capable of accurately reflecting the effect of $Z$ on $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c54a5",
   "metadata": {},
   "source": [
    "## 3.3. Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "\n",
    "def linear_dgp(n, beta, gamma, sigma_u=1):\n",
    "    X = np.random.normal(0, 1, n)\n",
    "    Z = np.random.normal(0, 1, n)\n",
    "    u = np.random.normal(0, sigma_u, n)\n",
    "    y = X * beta + Z * gamma + u\n",
    "    return y, np.column_stack((np.ones(n), X, Z))\n",
    "\n",
    "def estimate_ols(y, X):\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model.params, model.bse\n",
    "\n",
    "n = 1000\n",
    "beta = 1\n",
    "gamma_range = np.linspace(0, 1, 11)\n",
    "results = []\n",
    "\n",
    "# Estimating b(0)\n",
    "y, X = linear_dgp(n, beta, 0)\n",
    "b0, se_b0 = estimate_ols(y, X)[0][1], estimate_ols(y, X)[1][1]\n",
    "\n",
    "# Estimating b(gamma) for various gamma and conducting hypothesis tests\n",
    "p_values = []\n",
    "for gamma in gamma_range:\n",
    "    y, X = linear_dgp(n, beta, gamma)\n",
    "    b_gamma, se_gamma = estimate_ols(y, X)[0][1], estimate_ols(y, X)[1][1]\n",
    "    t_stat = (b_gamma - b0) / np.sqrt(se_b0**2 + se_gamma**2)\n",
    "    df = n - 3  # n - number of parameters estimated (intercept, beta, gamma)\n",
    "    p_val = 2 * t.sf(np.abs(t_stat), df)\n",
    "    p_values.append(p_val)\n",
    "    results.append((gamma, b_gamma, se_gamma, p_val))\n",
    "\n",
    "# Define region A\n",
    "region_A = [gamma_range[i] for i, p in enumerate(p_values) if p > 0.05]\n",
    "\n",
    "# Output region A\n",
    "print(\"Region A where the null hypothesis is not rejected:\", region_A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf9b72",
   "metadata": {},
   "source": [
    "## 3.2.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "def linear_dgp(n, beta, gamma, sigma_u=1, sigma_XZ=0):\n",
    "    \"\"\"\n",
    "    Generates data for the model y = Xβ + Zγ + u with a specified covariance between X and Z.\n",
    "    - n: Number of observations\n",
    "    - beta: Coefficient for X\n",
    "    - gamma: Coefficient for Z\n",
    "    - sigma_u: Standard deviation of the error term\n",
    "    - sigma_XZ: Covariance between X and Z\n",
    "    \"\"\"\n",
    "    # Generate X\n",
    "    X = np.random.normal(0, 1, n)\n",
    "    # Generate Z with specified covariance with X\n",
    "    Z = np.random.normal(sigma_XZ * X, np.sqrt(1 - sigma_XZ**2), n)\n",
    "    u = np.random.normal(0, sigma_u, n)\n",
    "    y = X * beta + Z * gamma + u\n",
    "    return y, np.column_stack((np.ones(n), X, Z))\n",
    "\n",
    "def estimate_ols(y, X):\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model.params, model.bse\n",
    "\n",
    "# Simulation settings\n",
    "n = 1000\n",
    "beta = 1\n",
    "gammas = np.linspace(0, 1, 5)  # Fewer points for simplicity in the example\n",
    "sigma_XZs = np.linspace(0, 1, 5)  # Covariance values from 0 to 1\n",
    "results = []\n",
    "\n",
    "# Estimating b(0) with no covariance\n",
    "y, X = linear_dgp(n, beta, 0, sigma_XZ=0)\n",
    "b0, se_b0 = estimate_ols(y, X)[0][1], estimate_ols(y, X)[1][1]\n",
    "\n",
    "# Nested loop for gamma and sigma_XZ values\n",
    "for gamma in gammas:\n",
    "    for sigma_XZ in sigma_XZs:\n",
    "        y, X = linear_dgp(n, beta, gamma, sigma_XZ=sigma_XZ)\n",
    "        b_gamma_sigmaXZ, se_gamma_sigmaXZ = estimate_ols(y, X)[0][1], estimate_ols(y, X)[1][1]\n",
    "        t_stat = (b_gamma_sigmaXZ - b0) / np.sqrt(se_b0**2 + se_gamma_sigmaXZ**2)\n",
    "        df = n - 3  # n - number of parameters estimated\n",
    "        p_val = 2 * t.sf(np.abs(t_stat), df)\n",
    "        results.append((gamma, sigma_XZ, b_gamma_sigmaXZ, p_val))\n",
    "\n",
    "# Define set B where the null hypothesis is not rejected\n",
    "set_B = [(gamma, sigma_XZ) for gamma, sigma_XZ, _, p_val in results if p_val > 0.05]\n",
    "\n",
    "# Print set B\n",
    "print(\"Set B where the null hypothesis is not rejected:\", set_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f9324",
   "metadata": {},
   "source": [
    "## Angrist-Krueger (1991) Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e16411",
   "metadata": {},
   "source": [
    "### What is the (implicit) identifying assumption? Comment on its plausibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28971e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1933 1930 1937 1935 1938 1939 1936 1934 1931 1932]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import inv, sqrtm\n",
    "import statsmodels.api as sm\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# Read in the data file\n",
    "ak_data = pd.read_stata('../../angrist-krueger91.dta')\n",
    "ak_data['yob1'] = ak_data['yob']\n",
    "# Print distinct years in the data\n",
    "print(ak_data['yob'].unique()) # Years are already filtered to 1930-1939 cohort\n",
    "# Add a constant to the data\n",
    "ak_data = sm.add_constant(ak_data)\n",
    "# Add dummy variables for each year of birth and each region minus one \n",
    "ak_data = pd.get_dummies(ak_data, columns=['yob', 'region', 'qob'], drop_first=True) \n",
    "# Dummy variables get coded as boolean - recode as 0/1 dummies\n",
    "for column in ak_data.columns:\n",
    "    if ak_data[column].dtype == 'bool':\n",
    "        ak_data[column] = ak_data[column].astype(int)\n",
    "ak_data['ageq_sq'] = ak_data['ageq']**2\n",
    "# Create yob*qob interaction terms\n",
    "for i in range(9):\n",
    "    for j in range(3):\n",
    "        ak_data['yob_193'+str(i+1)+'_qob_'+str(j+2)] = ak_data['yob_193'+str(i+1)]*ak_data['qob_'+str(j+2)]     \n",
    "# Create outcome variable equal to log wage\n",
    "y = ak_data[['logwage']]\n",
    "# Create regressor list for ease when creating regressions\n",
    "yob_dummies = ['yob_1931', 'yob_1932', 'yob_1933', 'yob_1934', 'yob_1935', 'yob_1936', 'yob_1937', 'yob_1938', 'yob_1939']\n",
    "region_dummies = ['region_1.0', 'region_2.0', 'region_3.0', 'region_4.0', 'region_5.0', 'region_6.0', 'region_7.0', 'region_8.0']\n",
    "qob_dummies = ['qob_2', 'qob_3', 'qob_4']\n",
    "interaction_dummies = [\n",
    "    'yob_1931_qob_2','yob_1931_qob_3','yob_1931_qob_4','yob_1932_qob_2','yob_1932_qob_3','yob_1932_qob_4',\n",
    "    'yob_1933_qob_2','yob_1933_qob_3','yob_1933_qob_4','yob_1934_qob_2','yob_1934_qob_3','yob_1934_qob_4',\n",
    "    'yob_1935_qob_2','yob_1935_qob_3','yob_1935_qob_4','yob_1936_qob_2','yob_1936_qob_3','yob_1936_qob_4',\n",
    "    'yob_1937_qob_2','yob_1937_qob_3','yob_1937_qob_4','yob_1938_qob_2','yob_1938_qob_3','yob_1938_qob_4',\n",
    "    'yob_1939_qob_2','yob_1939_qob_3','yob_1939_qob_4'\n",
    "]\n",
    "\n",
    "# The 'state' variable for some reason goes from 1-56, with some missing values (e.g. 3 is missing).\n",
    "# We will recode this variable to start from 1 and be sequential\n",
    "# Get the unique state codes from the 'state' column, sorted\n",
    "unique_states = sorted(ak_data['state'].unique())\n",
    "# Create a mapping from old state codes to new sequential codes starting from 1\n",
    "state_mapping = {old_code: new_code for new_code, old_code in enumerate(unique_states, start=1)}\n",
    "# Now apply this mapping to the 'state' column to create a new 'state' column\n",
    "ak_data['state_recode'] = ak_data['state'].map(state_mapping)\n",
    "\n",
    "# Create dummy variables from the new sequential state column\n",
    "ak_data = pd.get_dummies(ak_data, columns=['state_recode'], drop_first=True)\n",
    "# Ensure all boolean columns are converted to integers\n",
    "for column in ak_data.columns:\n",
    "    if ak_data[column].dtype == bool:\n",
    "        ak_data[column] = ak_data[column].astype(int)\n",
    "        \n",
    "# Create qob*state interaction terms\n",
    "\n",
    "# Number of qobs and states\n",
    "num_qobs = 4\n",
    "num_states = 51\n",
    "for i in range(2, num_qobs + 1):  # qobs start from 2 since the first qob is dropped\n",
    "    for j in range(2, num_states + 1):  # states start from 2 since the first state is dropped\n",
    "        qob_col = f'qob_{i}'\n",
    "        state_col = f'state_recode_{j}'\n",
    "        interaction_col = f'{qob_col}_state_{j}'\n",
    "        if qob_col in ak_data.columns and state_col in ak_data.columns:\n",
    "            ak_data[interaction_col] = ak_data[qob_col] * ak_data[state_col]\n",
    "        else:\n",
    "            print(f\"Column does not exist: {qob_col} or {state_col}\")\n",
    "\n",
    "# Create the state and state_qob_interactions lists\n",
    "state_dummies = [f'state_recode_{i}' for i in range(2, num_states + 1)]\n",
    "state_qob_interactions = [f'qob_{i}_state_{j}' for i in range(2, num_qobs + 1) for j in range(2, num_states + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da03f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS function\n",
    "def OLS(Y,X):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    XX = np.transpose(X)@X\n",
    "    XX_inv = np.linalg.pinv(XX)\n",
    "    XY = np.transpose(X)@Y\n",
    "    Beta_OLS = XX_inv@XY\n",
    "    N = Y.shape[0]\n",
    "    resid = Y - X@Beta_OLS \n",
    "    resid_var = (np.sum(np.square(resid)))/(N-1)\n",
    "    var_covar = resid_var*XX_inv \n",
    "    K = XX.shape[0]\n",
    "    SE = np.zeros(K)\n",
    "    for i in range(K):\n",
    "          SE[i] = np.sqrt(var_covar[i,i])\n",
    "    t = (1/SE)*Beta_OLS\n",
    "    return Beta_OLS, SE, var_covar,t\n",
    "\n",
    "# IV (2SLS) estimator function:\n",
    "def IV2SLS(Y,X,Z):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Z = np.array(Z)\n",
    "    ZX = np.transpose(Z)@X\n",
    "    ZX_inv = np.linalg.pinv(ZX)\n",
    "    ZY = np.transpose(Z)@Y\n",
    "    ZZ = np.transpose(Z)@Z\n",
    "    ZZ_inv = np.linalg.pinv(ZZ)\n",
    "    Beta_IV2SLS = np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)@(np.transpose(ZX)@ZZ_inv@ZY)\n",
    "    e = Y - X@Beta_IV2SLS\n",
    "    SSR = np.transpose(e)@e\n",
    "    N = X.shape[0]\n",
    "    vcv_IV2SLS = (SSR/N)*np.linalg.pinv(np.transpose(ZX)@ZZ_inv@ZX)\n",
    "    K = X.shape[1]\n",
    "    SE_IV2SLS = np.zeros(K)\n",
    "    for i in range(K):\n",
    "          SE_IV2SLS[i] = np.sqrt(vcv_IV2SLS[i,i])\n",
    "    t_IV2SLS = (1/SE_IV2SLS)*Beta_IV2SLS\n",
    "    return Beta_IV2SLS, SE_IV2SLS, vcv_IV2SLS,t_IV2SLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26c08bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0632\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2575\n",
      "Race OLS SE: 0.004\n",
      "SMSA OLS estimate:  0.1763\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2479\n",
      "Married OLS SE: 0.0032\n",
      "Age OLS estimate:  -0.076\n",
      "Age OLS SE: 0.0604\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth OLS - Column 7\n",
    "X4 = ak_data[['const', 'edu', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies]\n",
    "OLS4 = OLS(y,X4)\n",
    "Coeff4 = OLS4[0]\n",
    "SE4 = OLS4[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff4[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE4[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff4[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE4[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff4[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE4[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff4[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE4[4],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff4[5][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE4[5],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff4[6][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE4[6],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b1a74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.05995\n",
      "Education TSLS SE: 0.029\n",
      "Race TSLS estimate:  -0.2626\n",
      "Race TSLS SE: 0.0458\n",
      "SMSA TSLS estimate:  0.1797\n",
      "SMSA TSLS SE: 0.0305\n",
      "Married TSLS estimate:  0.2486\n",
      "Married TSLS SE: 0.0073\n",
      "Age TSLS estimate:  -0.0741\n",
      "Age TSLS SE: 0.0626\n",
      "Age Squared TSLS estimate:  0.0007\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth 2SLS - Column 8\n",
    "Z4 = ak_data[['const', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + qob_dummies + interaction_dummies]\n",
    "TSLS4 = IV2SLS(y,X4,Z4)\n",
    "Coeff_TSLS4 = TSLS4[0]\n",
    "SE_TSLS4 = TSLS4[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff_TSLS4[1][0],5))\n",
    "print(\"Education TSLS SE:\", np.round(SE_TSLS4[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff_TSLS4[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE_TSLS4[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff_TSLS4[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE_TSLS4[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff_TSLS4[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE_TSLS4[4],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff_TSLS4[5][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE_TSLS4[5],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff_TSLS4[6][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE_TSLS4[6],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551b607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education OLS estimate:  0.0628\n",
      "Education OLS SE: 0.0003\n",
      "Race OLS estimate:  -0.2547\n",
      "Race OLS SE: 0.0043\n",
      "SMSA OLS estimate:  0.1705\n",
      "SMSA OLS SE: 0.0029\n",
      "Married OLS estimate:  0.2487\n",
      "Married OLS SE: 0.0032\n",
      "Age OLS estimate:  -0.0778\n",
      "Age OLS SE: 0.0603\n",
      "Age Squared OLS estimate:  0.0008\n",
      "Age Squared OLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth OLS - Column 7\n",
    "X2_4 = ak_data[['const', 'edu', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + state_dummies]\n",
    "OLS2_4 = OLS(y,X2_4)\n",
    "Coeff2_4 = OLS2_4[0]\n",
    "SE2_4 = OLS2_4[1]\n",
    "print(\"Education OLS estimate: \", np.round(Coeff2_4[1][0],4))\n",
    "print(\"Education OLS SE:\", np.round(SE2_4[1],4))\n",
    "print(\"Race OLS estimate: \", np.round(Coeff2_4[2][0],4))\n",
    "print(\"Race OLS SE:\", np.round(SE2_4[2],4))\n",
    "print(\"SMSA OLS estimate: \", np.round(Coeff2_4[3][0],4))\n",
    "print(\"SMSA OLS SE:\", np.round(SE2_4[3],4))\n",
    "print(\"Married OLS estimate: \", np.round(Coeff2_4[4][0],4))\n",
    "print(\"Married OLS SE:\", np.round(SE2_4[4],4))\n",
    "print(\"Age OLS estimate: \", np.round(Coeff2_4[5][0],4))\n",
    "print(\"Age OLS SE:\", np.round(SE2_4[5],4))\n",
    "print(\"Age Squared OLS estimate: \", np.round(Coeff2_4[6][0],4))\n",
    "print(\"Age Squared OLS SE:\", np.round(SE2_4[6],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8a67f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education TSLS estimate:  0.08106\n",
      "Education TSLS SE: 0.0109\n",
      "Race TSLS estimate:  -0.2354\n",
      "Race TSLS SE: 0.0122\n",
      "SMSA TSLS estimate:  0.1531\n",
      "SMSA TSLS SE: 0.0107\n",
      "Married TSLS estimate:  0.2441\n",
      "Married TSLS SE: 0.0042\n",
      "Age TSLS estimate:  -0.0876\n",
      "Age TSLS SE: 0.0609\n",
      "Age Squared TSLS estimate:  0.0009\n",
      "Age Squared TSLS SE: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Fourth 2SLS - Column 8\n",
    "Z2_4 = ak_data[['const', 'black', 'smsa', 'married', 'ageq', 'ageq_sq'] + yob_dummies + region_dummies + qob_dummies + interaction_dummies + state_dummies + state_qob_interactions]\n",
    "TSLS2_4 = IV2SLS(y,X2_4,Z2_4)\n",
    "Coeff2_TSLS4 = TSLS2_4[0]\n",
    "SE2_TSLS4 = TSLS2_4[1]\n",
    "print(\"Education TSLS estimate: \", np.round(Coeff2_TSLS4[1][0],5))\n",
    "print(\"Education TSLS SE:\", np.round(SE2_TSLS4[1],4))\n",
    "print(\"Race TSLS estimate: \", np.round(Coeff2_TSLS4[2][0],4))\n",
    "print(\"Race TSLS SE:\", np.round(SE2_TSLS4[2],4))\n",
    "print(\"SMSA TSLS estimate: \", np.round(Coeff2_TSLS4[3][0],4))\n",
    "print(\"SMSA TSLS SE:\", np.round(SE2_TSLS4[3],4))\n",
    "print(\"Married TSLS estimate: \", np.round(Coeff2_TSLS4[4][0],4))\n",
    "print(\"Married TSLS SE:\", np.round(SE2_TSLS4[4],4))\n",
    "print(\"Age TSLS estimate: \", np.round(Coeff2_TSLS4[5][0],4))\n",
    "print(\"Age TSLS SE:\", np.round(SE2_TSLS4[5],4))\n",
    "print(\"Age Squared TSLS estimate: \", np.round(Coeff2_TSLS4[6][0],4))\n",
    "print(\"Age Squared TSLS SE:\", np.round(SE2_TSLS4[6],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3e5d5",
   "metadata": {},
   "source": [
    "### Adapt your implementation of the Chernozhukov and Hansen estimator to estimate the key parameter ρ, first for the Table 5 specification, then the Table 7 specification. How does your point estimate compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6c10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def first_stage_iv(df, formula):\n",
    "    \"\"\"\n",
    "    Perform the first stage of the IV estimation.\n",
    "    \n",
    "    :param df: DataFrame containing the data\n",
    "    :param formula: A Patsy formula for the IV regression (e.g., 'D ~ 1 + Z + X')\n",
    "    :return: DataFrame with the predicted values of the endogenous variable\n",
    "    \"\"\"\n",
    "    model = smf.ols(formula, data=df)\n",
    "    results = model.fit()\n",
    "    df['D_hat'] = results.fittedvalues\n",
    "    return df\n",
    "\n",
    "def quantile_regression(df, quantile, formula):\n",
    "    \"\"\"\n",
    "    Perform the quantile regression for the given quantile.\n",
    "    \n",
    "    :param df: DataFrame containing the data including the predicted D from the first stage\n",
    "    :param quantile: Quantile for which the regression should be performed (e.g., 0.5 for median)\n",
    "    :param formula: A Patsy formula for the quantile regression (e.g., 'Y ~ 1 + D_hat + X')\n",
    "    :return: QuantReg results instance\n",
    "    \"\"\"\n",
    "    mod = smf.quantreg(formula, df)\n",
    "    res = mod.fit(q=quantile)\n",
    "    return res\n",
    "def iv_quantile_treatment_effect(df, iv_formula, qr_formula, quantile):\n",
    "    \"\"\"\n",
    "    Estimate the IV quantile treatment effect.\n",
    "    \n",
    "    :param df: DataFrame with the data\n",
    "    :param iv_formula: Formula for the first stage IV\n",
    "    :param qr_formula: Formula for the quantile regression\n",
    "    :param quantile: Quantile to estimate\n",
    "    :return: Results of the quantile regression\n",
    "    \"\"\"\n",
    "    df_with_dhat = first_stage_iv(df, iv_formula)\n",
    "    qr_results = quantile_regression(df_with_dhat, quantile, qr_formula)\n",
    "    return qr_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df9afe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   Pseudo R-squared:               0.1108\n",
      "Model:                       QuantReg   Bandwidth:                     0.02899\n",
      "Method:                 Least Squares   Sparsity:                        1.014\n",
      "Date:                Tue, 16 Apr 2024   No. Observations:               329509\n",
      "Time:                        17:09:05   Df Residuals:                   329501\n",
      "                                        Df Model:                            7\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.7290      3.162      2.444      0.015       1.531      13.927\n",
      "D_hat         -0.0055      0.003     -1.736      0.083      -0.012       0.001\n",
      "const          7.7288      3.162      2.444      0.015       1.530      13.927\n",
      "edu            0.0613      0.000    222.974      0.000       0.061       0.062\n",
      "black         -0.2325      0.003    -70.915      0.000      -0.239      -0.226\n",
      "smsa           0.1712      0.002     74.614      0.000       0.167       0.176\n",
      "married        0.1915      0.003     74.195      0.000       0.186       0.197\n",
      "ageq           0.0083      0.011      0.749      0.454      -0.013       0.030\n",
      "ageq_sq       -0.0001      0.000     -0.867      0.386      -0.000       0.000\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 1.19e+09. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "iv_formula = 'yob1 ~ 1 + const + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + qob_dummies + interaction_dummies) + ' + edu'\n",
    "qr_formula = 'logwage ~ 1 + D_hat + const + edu + black + smsa + married + ageq + ageq_sq'\n",
    "# Running the IV quantile treatment effect\n",
    "results = iv_quantile_treatment_effect(ak_data, iv_formula, qr_formula, 0.5)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04e47794",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "iv_formula = 'yob1 ~ 1 + const + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + qob_dummies + interaction_dummies) + ' + edu'\n",
    "qr_formula = 'logwage ~ 1 + D_hat + const + edu + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + state_dummies)\n",
    "# Running the IV quantile treatment effect\n",
    "results = iv_quantile_treatment_effect(ak_data, iv_formula, qr_formula, 0.5)\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "064e67b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   Pseudo R-squared:               0.1108\n",
      "Model:                       QuantReg   Bandwidth:                     0.02899\n",
      "Method:                 Least Squares   Sparsity:                        1.014\n",
      "Date:                Tue, 16 Apr 2024   No. Observations:               329509\n",
      "Time:                        16:57:54   Df Residuals:                   329501\n",
      "                                        Df Model:                            7\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.7294      3.162      2.444      0.015       1.531      13.928\n",
      "D_hat         -0.0055      0.003     -1.736      0.082      -0.012       0.001\n",
      "const          7.7295      3.162      2.444      0.015       1.531      13.928\n",
      "edu            0.0613      0.000    222.974      0.000       0.061       0.062\n",
      "black         -0.2325      0.003    -70.915      0.000      -0.239      -0.226\n",
      "smsa           0.1712      0.002     74.615      0.000       0.167       0.176\n",
      "married        0.1915      0.003     74.195      0.000       0.186       0.197\n",
      "ageq           0.0083      0.011      0.749      0.454      -0.013       0.030\n",
      "ageq_sq       -0.0001      0.000     -0.867      0.386      -0.000       0.000\n",
      "==============================================================================\n",
      "\n",
      "The smallest eigenvalue is -4.42e-08. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "iv_formula = 'yob1 ~ 1 + const + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + qob_dummies + interaction_dummies + state_dummies + state_qob_interactions) + ' + edu'\n",
    "qr_formula = 'logwage ~ 1 + D_hat + const + edu + black + smsa + married + ageq + ageq_sq '\n",
    "# Running the IV quantile treatment effect\n",
    "results = iv_quantile_treatment_effect(ak_data, iv_formula, qr_formula, 0.5)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a322110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   Pseudo R-squared:               0.1129\n",
      "Model:                       QuantReg   Bandwidth:                     0.02523\n",
      "Method:                 Least Squares   Sparsity:                        1.273\n",
      "Date:                Tue, 16 Apr 2024   No. Observations:               329509\n",
      "Time:                        17:11:01   Df Residuals:                   329501\n",
      "                                        Df Model:                            7\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      6.6758      3.438      1.942      0.052      -0.063      13.414\n",
      "D_hat         -0.0044      0.003     -1.266      0.206      -0.011       0.002\n",
      "const          6.6764      3.438      1.942      0.052      -0.062      13.415\n",
      "edu            0.0607      0.000    196.557      0.000       0.060       0.061\n",
      "black         -0.2086      0.004    -58.664      0.000      -0.216      -0.202\n",
      "smsa           0.1504      0.002     60.598      0.000       0.146       0.155\n",
      "married        0.1442      0.003     51.412      0.000       0.139       0.150\n",
      "ageq           0.0153      0.012      1.277      0.202      -0.008       0.039\n",
      "ageq_sq       -0.0002      0.000     -1.241      0.215      -0.000    9.18e-05\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 1.19e+09. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "iv_formula = 'yob1 ~ 1 + const + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + qob_dummies + interaction_dummies) + ' + edu'\n",
    "qr_formula = 'logwage ~ 1 + D_hat + const + edu + black + smsa + married + ageq + ageq_sq'\n",
    "# Running the IV quantile treatment effect\n",
    "results = iv_quantile_treatment_effect(ak_data, iv_formula, qr_formula, 0.75)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b764c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   Pseudo R-squared:               0.1129\n",
      "Model:                       QuantReg   Bandwidth:                     0.02523\n",
      "Method:                 Least Squares   Sparsity:                        1.273\n",
      "Date:                Tue, 16 Apr 2024   No. Observations:               329509\n",
      "Time:                        17:11:38   Df Residuals:                   329501\n",
      "                                        Df Model:                            7\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      6.6757      3.438      1.942      0.052      -0.063      13.414\n",
      "D_hat         -0.0044      0.003     -1.266      0.206      -0.011       0.002\n",
      "const          6.6757      3.438      1.942      0.052      -0.063      13.414\n",
      "edu            0.0607      0.000    196.557      0.000       0.060       0.061\n",
      "black         -0.2086      0.004    -58.664      0.000      -0.216      -0.202\n",
      "smsa           0.1504      0.002     60.598      0.000       0.146       0.155\n",
      "married        0.1442      0.003     51.412      0.000       0.139       0.150\n",
      "ageq           0.0153      0.012      1.277      0.202      -0.008       0.039\n",
      "ageq_sq       -0.0002      0.000     -1.241      0.215      -0.000    9.18e-05\n",
      "==============================================================================\n",
      "\n",
      "The smallest eigenvalue is -4.42e-08. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "/Users/alineabayo/anaconda3/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "iv_formula = 'yob1 ~ 1 + const + black + smsa + married + ageq + ageq_sq + ' + ' + '.join(yob_dummies + qob_dummies + interaction_dummies + state_dummies + state_qob_interactions) + ' + edu'\n",
    "qr_formula = 'logwage ~ 1 + D_hat + const + edu + black + smsa + married + ageq + ageq_sq '\n",
    "# Running the IV quantile treatment effect\n",
    "results = iv_quantile_treatment_effect(ak_data, iv_formula, qr_formula, 0.75)\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
