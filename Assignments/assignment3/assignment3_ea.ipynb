{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Eleanor Adachi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team's code can be found here: https://github.com/eleanor-adachi/ARE212_Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exercises (GMM)\n",
    "\n",
    "When we approach a new estimation problem from a GMM perspective there’s a simple set of steps we can follow.\n",
    "- Describe the parameter space B;\n",
    "- Describe a function gj(b) such that Egj(β) = 0;\n",
    "- Describe an estimator for the covariance matrix Egj(β)gj(β)⊤.\n",
    "\n",
    "### (1) Explain how the steps outlined above can be used to construct an optimally weighted GMM estimator.\n",
    "\n",
    "### (2) Consider the following models. For each, provide a causal diagram; construct the optimally weighted GMM estimator of the unknown parameters (various Greek letters); and give an estimator for the covariance matrix of your estimates. If any additional assumptions are required for your estimator to be identified please provide these.\n",
    "\n",
    "#### (a) $\\mathbb{E}y = \\mu; \\mathbb{E}(y − \\mu)^2 = \\sigma^2; \\mathbb{E}(y − \\mu)^3 = 0$.  *Note: $y$ is a random variable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) $y = \\alpha + X \\beta + u$; with $\\mathbb{E}(X^T u) = \\mathbb{E}u = 0$.  *Note: $y$, $X$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) $y = \\alpha + X \\beta + u$; with $\\mathbb{E}(X^T u) = \\mathbb{E}u = 0$, and $\\mathbb{E}(u^2) = \\sigma^2$.  *Note: $y$, $X$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) $y = \\alpha + X \\beta + u$; with $\\mathbb{E}(X^Tu) = \\mathbb{E}u = 0$, and $\\mathbb{E}(u^2) = e^{X \\sigma}$.  *Note: $y$, $X$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) $y = \\alpha + X \\beta + u$; with $\\mathbb{E}(Z^⊤u) = \\mathbb{E}u = 0$ and $\\mathbb{E}Z^⊤ X = Q$.  *Note: $y$, $X$, $Z$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) $y = f(X \\beta) + u$; with $f$ a known scalar function and with $\\mathbb{E}(Z^⊤u) = \\mathbb{E}u = 0$ and $\\mathbb{E}Z^⊤ X f'(X \\beta) = Q(\\beta)$. (Bonus question: where does this last restriction come from, and what role does it play?)  *Note: $y$, $X$, $Z$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (g) $y = f(X, \\beta) + u$; with $f$ a known function and with $\\mathbb{E}(Z^⊤u) = \\mathbb{E}u = 0$ and $\\mathbb{E}Z^⊤ \\frac{\\partial f}{\\partial \\beta^T} (X, \\beta) = Q(\\beta)$.  *Note: $y$, $X$, $Z$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (h) $y^\\gamma = \\alpha + u$, with $y > 0$ and $\\gamma$ a scalar, and $\\mathbb{E}(Z^⊤u) = \\mathbb{E}u = 0$ and $\\mathbb{E}Z^⊤ \\begin{bmatrix} \\gamma y^{\\gamma − 1} \\\\ −1 \\end{bmatrix} = Q(\\gamma)$.  *Note: $y$, $Z$, and $u$ are random variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) For each of the models above write a data-generating process in python. Your function `dgp` should take as arguments a sample size $N$ and a vector of \"true\" parameters `b0`, and return a dataset $(y, X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Select the most interesting of the data generating processes you developed, and using the code in `gmm.py` or `GMM_class.py` (see https://github.com/ligonteaching/ARE212_Materials/) use data from your `dgp` to analyze the finite sample performance of the corresponding GMM estimator you’ve constructed. Of particular interest is the distribution of your estimator using a sample size $N$ and how this distribution compares with the limiting distribution as $N \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercises (Cross-Validation)\n",
    "\n",
    "Consider estimation of a linear model $y = X \\beta + u$, with the identifying\n",
    "assumption that $\\mathbb{E}(u|X) = 0$.\n",
    "\n",
    "When we compute K-fold cross-validation of a tuning parameter $\\lambda$ (e.g., the penalty parameter in a LASSO regression), then for each value of $\\lambda$ we obtain $K$ estimates of any given parameter, say $\\beta_i$; denote the estimates of this parameter by $b_i^. = (b_i^1 , . . . , b_i^K)$. If our total sample (say $D_1$) comprises $N$ iid observations, then each of our $K$ estimates will be based on a sample $D_1^k$ of roughly $N \\frac{K−1}{K}$ observations.\n",
    "\n",
    "### (1) How can you use the estimates $b_i^.$ to estimate the variance of the estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) What can you say about the variance of your estimator of the variance? In particular, how does it vary with $K$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Breusch-Pagan Extended\n",
    "\n",
    "Consider a linear regression of the form\n",
    "\n",
    "$y = \\alpha + \\beta x + u$,\n",
    "\n",
    "with $(y, x)$ both scalar random variables, where it is assumed that (a.i) $\\mathbb{E}(u \\cdot x) = \\mathbb{E}u = 0$ and (a.ii) $\\mathbb{E}(u^2|x) = \\sigma^2$.\n",
    "\n",
    "### (1) The condition a.i is essentially untestable; explain why.\n",
    "\n",
    "### (2) Breusch and Pagan (1979) argue that one can test a.ii via an auxiliary regression $\\hat{u}^2 = c+dx+e$, where the $\\hat{u}$ are the residuals from the first regression, and the test of a.ii then becomes a test of $H_0 : d = 0$. Describe the logic of the test of a.ii.\n",
    "\n",
    "### (3) Use the two conditions a.i and a.ii to construct a GMM version of the Breusch-Pagan test.\n",
    "\n",
    "### (4) What can you say about the performance or relative merits of the Breusch-Pagan test versus your GMM alternative?\n",
    "\n",
    "### (5) Suppose that in fact that $x$ is distributed uniformly over the interval $[0, 2\\pi]$, and $\\mathbb{E}(u^2|x) = \\sigma^2(x) = \\sigma^2 sin(2x)$, thus violating a.ii. What can you say about the performance of the Breusch-Pagan test in this circumstance? Can you modify your GMM test to provide a superior alternative?\n",
    "\n",
    "### (6) In the above, we’ve considered a test of a specific functional form for the variance of $u$. Suppose instead that we don’t have any prior information regarding the form of $\\mathbb{E}(u^2|x) = f(x)$. Discuss how you might go about constructing an extended version of the Breusch-Pagan test which tests for $f(x)$ non-constant.\n",
    "\n",
    "### (7) Show that you can use your ideas about estimating $f(x)$ to construct a more efficient estimator of $\\beta$ if $f(x)$ isn’t constant. Relate your estimator to the optimal generalized least squares (GLS) estimator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
